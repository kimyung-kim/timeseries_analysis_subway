{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "대표적으로 유형이 다른 역 5개를 뽑아서 Modeling 진행\n",
    "\n",
    "선행연구는 코로나를 반영 안하고 LSTM을 이용해서 2023년 1월 ~ 3월 : train / 2023년 4월 : test\n",
    "\n",
    "코로나의 경우 코로나 정책에서 따라 change point가 생김\n",
    "\n",
    "따라서, 본 프로젝트에서는 change point를 찾아내고 그 원인을 분석하고 이를 바탕으로 modeling 진행하기\n",
    "\n",
    "train data : 2019년 ~ 2022년 / test : 2023년"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from lib import grid_search as gs\n",
    "from lib import get_data_per_station as sta\n",
    "from lib import change_point\n",
    "from lib import sarimax as sa\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. Load Datasets and Data Processing\n",
    "Data processing 과정 마무리 후 삭제 하였음. \n",
    "\n",
    "데이터 merge 작업과 추가 필요성이 있는 변수들을 추가하는 과정을 거짐.\n",
    "\n",
    "그 결과가 merged_data.csv\n",
    "\n",
    "holiday: 설, 추석 연휴 / social_distance_change : 1이면 단계를 올린 시점 -1이면 단계를 내린 시점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"data/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, forecast):\n",
    "    actual, forecast = np.array(actual), np.array(forecast)\n",
    "    return np.mean(np.abs((actual - forecast) / actual)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations = merged_df['역명'].unique()\n",
    "# num_people = [0]*len(stations)\n",
    "# for i in range(len(stations)):\n",
    "#     tmp = sta.get_data(merged_df, stations[i])\n",
    "#     num_people[i] = sum(tmp['승차총승객수']) + sum(tmp['하차총승객수'])\n",
    "# data = {'stations': stations, 'num_people': num_people}\n",
    "# tmp = pd.DataFrame(data).sort_values(by='num_people', ascending=False).head(15)\n",
    "# top_stations = np.array(tmp['stations'])\n",
    "# print(top_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15개의 역에 대해 그래프를 그린 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 1826\n",
    "# for k in range(15):\n",
    "#     df_station = sta.get_data(merged_df, top_stations[k])\n",
    "#     tmp = sta.get_tidy_data(df_station)\n",
    "#     print(top_stations[k])\n",
    "#     plt.plot(pd.Series(np.array(tmp['하차총승객수'] + tmp['승차총승객수']), index=pd.date_range('2019-01-01', periods=days, freq='D')))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_selected = ['잠실(송파구청)', '강남', '고속터미널', '서울역', '여의도']\n",
    "names = ['Jamsil Station', 'Gangnam Station', 'Express Bus Terminal', 'Seoul Station', 'Yeouido']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(5):\n",
    "#     df_station = sta.get_data(merged_df, station_selected[k])\n",
    "#     tmp = sta.get_tidy_data(df_station)\n",
    "#     plt.plot(pd.Series(np.array(tmp['하차총승객수'] + tmp['승차총승객수']), index=pd.date_range('2019-01-01', periods=days, freq='D')))\n",
    "#     plt.title(names[k])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = sta.get_data(merged_df, '잠실(송파구청)')\n",
    "tmp = sta.get_tidy_data(df_station)\n",
    "plt.plot(pd.Series(np.array(tmp['하차총승객수'] + tmp['승차총승객수'])[days-365:days], index=pd.date_range('2023-01-01', periods=365, freq='D')))\n",
    "plt.title(\"Jamsil Station, 2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.array(tmp['하차총승객수'] + tmp['승차총승객수'])[days-365:days], index=pd.date_range('2023-01-01', periods=365, freq='D'))\n",
    "stl = STL(ts); res = stl.fit()\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "ax1.plot(ts)\n",
    "ax1.set_title('Original Time Series')\n",
    "ax2.plot(res.trend)\n",
    "ax2.set_title('Trend Component')\n",
    "ax3.plot(res.seasonal)\n",
    "ax3.set_title('Seasonal Component')\n",
    "ax4.plot(res.resid)\n",
    "ax4.set_title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 설, 추석 연휴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = tmp[['사용일자', '승차총승객수', '하차총승객수', 'holiday']].copy()\n",
    "counts['사용일자'] = pd.to_datetime(counts['사용일자'], format='%Y%m%d')\n",
    "counts.set_index('사용일자', inplace=True)\n",
    "signal = (counts['승차총승객수'] + counts['하차총승객수']).values\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(counts.index, signal)\n",
    "ax.set_title('Lunar New Year and Chuseok for Jamsil Station')\n",
    "plt.xticks(rotation=45)\n",
    "plt.plot(pd.Series(np.array(counts['holiday']*50000), index=pd.date_range('2019-01-01', periods=days, freq='D')))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 잠실 : 4월 첫째주 주말, 크리스마스, and 어린이날"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [95, 96, 358, 1187, 1188, 1454, 1551, 1552, 1819, 124, 1220, 1585] #20, 21년 제외\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(counts.index, signal)\n",
    "for cp in index:\n",
    "   ax.axvline(counts.index[cp], color='red', linestyle='--')\n",
    "ax.set_title('Cherry blossom, christmas and children\\'s day for Jamsil Station except 20, 21')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잠실 송파구청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = sta.get_data(merged_df, '잠실(송파구청)')\n",
    "df = sta.get_tidy_data(df_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) change point detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point.detection(df, 1.5, ' Jamsil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [95, 96, 358, 1187, 1188, 1454, 1551, 1552, 1819, 124, 1220, 1585]  # 코로나 시절의 20, 21년도 제외 4월 첫주 휴일, 크리스마스 및 어린이날\n",
    "peak = [0]*days\n",
    "for i in range(days):\n",
    "    if i in index: peak[i] = 1\n",
    "df['peak_jamsil'] = peak\n",
    "df['total'] = df['승차총승객수'] + df['하차총승객수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['승차총승객수', '하차총승객수', 'is_semester', 'is_offline', 'offline_class', 'day_off'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/df_jamsil.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_jamsil.csv\")\n",
    "station_train = df[0:1461]; station_valid = df[1461:]\n",
    "\n",
    "train_data = pd.Series(np.array(station_train['total']), index=pd.date_range('2019-01-01', periods=1461, freq='D'))\n",
    "test_data = pd.Series(np.array(station_valid['total']), index=pd.date_range('2023-01-01', periods=365, freq='D'))\n",
    "\n",
    "exog_list = ['social_distance_change', 'peak_jamsil', 'holiday']\n",
    "exog_variables = sta.get_exog_variables(station_train, station_valid, exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = gs.find_best_parameter(train_data, test_data, exog_variables)\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 7, exog_variables[0], exog_variables[1], \"Jamsil Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 14, exog_variables[0], exog_variables[1], \"Jamsil Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Auto-Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model = auto_arima(train_data, seasonal=True, m=7, stepwise=False)\n",
    "print(ar_model)\n",
    "fitted = ar_model.fit(train_data).predict_in_sample()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(1, 1, 1), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(2, 1, 1), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 1), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 1), seasonal_order=(1, 0, 2, 7))\n",
    "print(model.fit().aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강남역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = sta.get_data(merged_df, '강남')\n",
    "df = sta.get_tidy_data(df_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Change Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point.detection(df, 1.5, ' Gangnam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [124, 1220, 1585] # 코로나 없던 어린이날에 change point\n",
    "peak = [0]*days\n",
    "for i in range(days):\n",
    "    if i in index: peak[i] = 1\n",
    "df['peak_gangnam'] = peak\n",
    "df['total'] = df['승차총승객수'] + df['하차총승객수']\n",
    "df.drop(columns=['승차총승객수', '하차총승객수', 'is_semester', 'is_offline', 'offline_class', 'day_off'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/df_gangnam.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_gangnam.csv\")\n",
    "station_train = df[0:1461]; station_valid = df[1461:]\n",
    "\n",
    "train_data = pd.Series(np.array(station_train['total']), index=pd.date_range('2019-01-01', periods=1461, freq='D'))\n",
    "test_data = pd.Series(np.array(station_valid['total']), index=pd.date_range('2023-01-01', periods=365, freq='D'))\n",
    "\n",
    "exog_list = ['social_distance_change', 'holiday', 'peak_gangnam']\n",
    "exog_variables = sta.get_exog_variables(station_train, station_valid, exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = gs.find_best_parameter(train_data, test_data, exog_variables)\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 7, exog_variables[0], exog_variables[1], \"Gangnam Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 14, exog_variables[0], exog_variables[1], \"Gangnam Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model = auto_arima(train_data, max_P=4, max_Q=4, seasonal=True, m=7, stepwise=False)\n",
    "print(ar_model)\n",
    "fitted = ar_model.fit(train_data).predict_in_sample()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(0, 1, 1), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 1), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(0, 1, 2), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(0, 1, 1), seasonal_order=(3, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(0, 1, 1), seasonal_order=(2, 0, 2, 7))\n",
    "print(model.fit().aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(0, 1, 1), seasonal_order=(2, 0, 1, 7))\n",
    "fitted = model.fit().predict()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여의도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = sta.get_data(merged_df, '여의도')\n",
    "df = sta.get_tidy_data(df_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Change Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point.detection(df, 1.5, ' Yeouido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1 = [276, 1375, 1740] #불꽃 축제\n",
    "peak_1 = [0]*days\n",
    "peak_2 = [0]*days\n",
    "for i in range(days):\n",
    "    if i in index_1: peak_1[i] = 1\n",
    "    #if i in index_2: peak_2[i] = 1\n",
    "df['peak_yeouido'] = peak_1\n",
    "#df['peak_yeouido_2'] = peak_2\n",
    "df['total'] = df['승차총승객수'] + df['하차총승객수']\n",
    "df.drop(columns=['승차총승객수', '하차총승객수', 'is_semester', 'is_offline', 'offline_class', 'day_off'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_yeouido.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_yeouido.csv\")\n",
    "station_train = df[0:1461]; station_valid = df[1461:]\n",
    "\n",
    "train_data = pd.Series(np.array(station_train['total']), index=pd.date_range('2019-01-01', periods=1461, freq='D'))\n",
    "test_data = pd.Series(np.array(station_valid['total']), index=pd.date_range('2023-01-01', periods=365, freq='D'))\n",
    "\n",
    "exog_list = ['social_distance_change', 'holiday', 'peak_yeouido']\n",
    "exog_variables = sta.get_exog_variables(station_train, station_valid, exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = gs.find_best_parameter(train_data, test_data, exog_variables)\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 7, exog_variables[0], exog_variables[1], \"Yeouido Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 14, exog_variables[0], exog_variables[1], \"Yeouido Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Auto-Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model = auto_arima(train_data, seasonal=True, m=7, stepwise=False)\n",
    "print(ar_model)\n",
    "fitted = ar_model.fit(train_data).predict_in_sample()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(2, 1, 2), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 3), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(1, 0, 2, 7))\n",
    "print(model.fit().aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고속터미널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = sta.get_data(merged_df, '고속터미널')\n",
    "df = sta.get_tidy_data(df_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Change point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point.detection(df, 1.5, ' Express Bus Treminal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1 = [124, 1220, 1585] #20 21 제외 어린이날\n",
    "index_2 = [35, 255, 389, 639, 773, 994, 1127, 1348, 1483, 1732] #설 당일, 추석 당일\n",
    "index_3 = [34, 36, 254, 256, 388, 390, 638, 640, 772, 774, 993, 995, 1126, 1128, 1347, 1349, 1482, 1484, 1731, 1733] #설, 추석 전날, 다음 날\n",
    "index_4 = [0, 364, 365, 730, 731, 1095, 1096, 1460, 1461, 1825] #새해 첫날, 마지막 날\n",
    "peak_1 = [0]*days\n",
    "peak_2 = [0]*days\n",
    "peak_3 = [0]*days\n",
    "peak_4 = [0]*days\n",
    "for i in range(days):\n",
    "    if i in index_1: peak_1[i] = 1\n",
    "    if i in index_2: peak_2[i] = 1\n",
    "    if i in index_3: peak_3[i] = 1\n",
    "    if i in index_4: peak_4[i] = 1\n",
    "df['peak_express_1'] = peak_1\n",
    "df['peak_express_2'] = peak_2\n",
    "df['peak_express_3'] = peak_3\n",
    "df['peak_express_4'] = peak_4\n",
    "df['total'] = df['승차총승객수'] + df['하차총승객수']\n",
    "df.drop(columns=['승차총승객수', '하차총승객수', 'is_semester', 'is_offline', 'offline_class', 'day_off'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/df_express_terminal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_express_terminal.csv\")\n",
    "station_train = df[0:1461]; station_valid = df[1461:]\n",
    "\n",
    "train_data = pd.Series(np.array(station_train['total']), index=pd.date_range('2019-01-01', periods=1461, freq='D'))\n",
    "test_data = pd.Series(np.array(station_valid['total']), index=pd.date_range('2023-01-01', periods=365, freq='D'))\n",
    "\n",
    "exog_list = ['social_distance_change', 'peak_express_1', 'peak_express_2', 'peak_express_3', 'peak_express_4']\n",
    "exog_variables = sta.get_exog_variables(station_train, station_valid, exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = gs.find_best_parameter(train_data, test_data, exog_variables)\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 7, exog_variables[0], exog_variables[1], \"Express Bus Terminal Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 14, exog_variables[0], exog_variables[1], \"Express Bus Terminal Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Auto Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model = auto_arima(train_data, seasonal=True, m=7, stepwise=False)\n",
    "print(ar_model)\n",
    "fitted = ar_model.fit(train_data).predict_in_sample()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(1, 1, 3), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(2, 1, 3), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 4), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 3), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 3), seasonal_order=(1, 0, 2, 7))\n",
    "print(model.fit().aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(1, 1, 3), seasonal_order=(1, 0, 1, 7))\n",
    "fitted = model.fit().predict()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서울역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = sta.get_data(merged_df, '서울역')\n",
    "df = sta.get_tidy_data(df_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Change point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point.detection(df, 1.5, ' Seoul Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1 = [124, 1220, 1585] #20 21 제외 어린이날\n",
    "index_2 = [35, 255, 389, 639, 773, 994, 1127, 1348, 1483, 1732] #설 당일, 추석 당일\n",
    "index_3 = [34, 36, 254, 256, 388, 390, 638, 640, 772, 774, 993, 995, 1126, 1128, 1347, 1349, 1482, 1484, 1731, 1733] #설, 추석 전날, 다음 날 \n",
    "peak_1 = [0]*days\n",
    "peak_2 = [0]*days\n",
    "peak_3 = [0]*days\n",
    "for i in range(days):\n",
    "    if i in index_1: peak_1[i] = 1\n",
    "    if i in index_2: peak_2[i] = 1\n",
    "    if i in index_3: peak_3[i] = 1\n",
    "df['peak_seoul_1'] = peak_1\n",
    "df['peak_seoul_2'] = peak_2\n",
    "df['peak_seoul_3'] = peak_3\n",
    "df['total'] = df['승차총승객수'] + df['하차총승객수']\n",
    "df.drop(columns=['승차총승객수', '하차총승객수', 'is_semester', 'is_offline', 'offline_class', 'day_off'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/df_seoul.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"data/df_seoul.csv\")\n",
    "station_train = df[0:1461]; station_valid = df[1461:]\n",
    "\n",
    "train_data = pd.Series(np.array(station_train['total']), index=pd.date_range('2019-01-01', periods=1461, freq='D'))\n",
    "test_data = pd.Series(np.array(station_valid['total']), index=pd.date_range('2023-01-01', periods=365, freq='D'))\n",
    "\n",
    "exog_list = ['social_distance_change', 'peak_seoul_1','peak_seoul_2', 'peak_seoul_3']\n",
    "exog_variables = sta.get_exog_variables(station_train, station_valid, exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = gs.find_best_parameter(train_data, test_data, exog_variables)\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 7, exog_variables[0], exog_variables[1], \"Seoul Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sarimax_result(train_data, test_data, best_parameter[0:3], best_parameter[3:6], 14, exog_variables[0], exog_variables[1], \"Seoul Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model = auto_arima(train_data, seasonal=True, m=7, stepwise=False)\n",
    "print(ar_model)\n",
    "fitted = ar_model.fit(train_data).predict_in_sample()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 3), seasonal_order=(1, 0, 1, 7)) #fitting error\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(2, 1, 2), seasonal_order=(1, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(2, 0, 1, 7))\n",
    "print(model.fit().aic)\n",
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(1, 0, 2, 7))\n",
    "print(model.fit().aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order=(1, 1, 2), seasonal_order=(1, 0, 1, 7))\n",
    "fitted = model.fit().predict()\n",
    "tr_rmse = np.sqrt(np.mean((fitted - train_data)**2))\n",
    "print(\"train RMSE :\", tr_rmse)\n",
    "print(\"train MAPE :\", mape(train_data, fitted))\n",
    "predictions = ar_model.predict(365)\n",
    "rmse = np.sqrt(np.mean((test_data - predictions)**2))\n",
    "print(\"test RMSE :\", rmse)\n",
    "print(\"test MAPE :\", mape(test_data, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
